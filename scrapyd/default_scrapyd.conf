[scrapyd]
# Application options
application       = scrapyd.app.application
bind_address      = 127.0.0.1
http_port         = 6800
unix_socket_path  =
username          =
password          =
spiderqueue       = scrapyd.spiderqueue.SqliteSpiderQueue

# Poller options
poller            = scrapyd.poller.QueuePoller
poll_interval     = 5.0

# Launcher options
launcher          = scrapyd.launcher.Launcher
max_proc          = 0
max_proc_per_cpu  = 4
logs_dir          = logs
items_dir         =
jobs_dir          =
jobs_to_keep      = 5
runner            = scrapyd.runner

# Web UI and API options
webroot           = scrapyd.website.Root
prefix_header     = x-forwarded-prefix
debug             = off

# Egg storage options
eggstorage        = scrapyd.eggstorage.FilesystemEggStorage
eggs_dir          = eggs

# Job storage options
jobstorage        = scrapyd.jobstorage.MemoryJobStorage
finished_to_keep  = 100

# Directory options
dbs_dir           = dbs

[services]
schedule.json     = scrapyd.webservice.Schedule
cancel.json       = scrapyd.webservice.Cancel
status.json       = scrapyd.webservice.Status
addversion.json   = scrapyd.webservice.AddVersion
listprojects.json = scrapyd.webservice.ListProjects
listversions.json = scrapyd.webservice.ListVersions
listspiders.json  = scrapyd.webservice.ListSpiders
delproject.json   = scrapyd.webservice.DeleteProject
delversion.json   = scrapyd.webservice.DeleteVersion
listjobs.json     = scrapyd.webservice.ListJobs
daemonstatus.json = scrapyd.webservice.DaemonStatus
